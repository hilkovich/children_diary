{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from evaluate import load\n",
    "from textwrap import wrap\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flickr30k датасет - состоит из 30 000 изображений, каждое из которых связано с пятью разными подписями,\n",
    "# обеспечивающими точное описание основных объектов и событий. В них нет известных людей или мест.\n",
    "# Демонстрирует разных сцен и ситуаций.\n",
    "ds_flickr30k = load_dataset(\"lmms-lab/flickr30k\")\n",
    "\n",
    "ds_flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция поиска в подписях изображений упоминаний про детей\n",
    "def check_for_children(caption_list):\n",
    "    keywords = [\"child\", \"kid\", \"baby\", \"toddler\", \"infant\"]\n",
    "    return any(\n",
    "        keyword in caption.lower() for keyword in keywords for caption in caption_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бинарная разметка датасета по наличию детей\n",
    "ds_flickr30k[\"test\"] = ds_flickr30k[\"test\"].add_column(\n",
    "    \"has_children\",\n",
    "    [check_for_children(example[\"caption\"]) for example in ds_flickr30k[\"test\"]],\n",
    ")\n",
    "\n",
    "# Фильтрация датасета только на детей\n",
    "filter_ds_flickr30k = ds_flickr30k[\"test\"].filter(\n",
    "    lambda example: example[\"has_children\"]\n",
    ")\n",
    "\n",
    "# Удаление лишней информации\n",
    "filter_ds_flickr30k = filter_ds_flickr30k.remove_columns(\n",
    "    [\"sentids\", \"has_children\", \"img_id\", \"filename\"]\n",
    ")\n",
    "\n",
    "filter_ds_flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NoCaps датасет - состоит из 166 100 созданных человеком подписей, описывающих 15 100 изображений\n",
    "# из проверочных и тестовых наборов Open Images.\n",
    "ds_nocaps = load_dataset(\"lmms-lab/NoCaps\")\n",
    "\n",
    "ds_nocaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бинарная разметка датасета по наличию детей\n",
    "ds_nocaps[\"validation\"] = ds_nocaps[\"validation\"].add_column(\n",
    "    \"has_children\",\n",
    "    [\n",
    "        check_for_children(example[\"annotations_captions\"])\n",
    "        for example in ds_nocaps[\"validation\"]\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Фильтрация датасета только на детей\n",
    "filter_ds_nocaps = ds_nocaps[\"validation\"].filter(\n",
    "    lambda example: example[\"has_children\"]\n",
    ")\n",
    "\n",
    "# Удаление лишней информации\n",
    "filter_ds_nocaps = filter_ds_nocaps.remove_columns(\n",
    "    [\n",
    "        \"annotations_ids\",\n",
    "        \"has_children\",\n",
    "        \"image_open_images_id\",\n",
    "        \"image_license\",\n",
    "        \"image_width\",\n",
    "        \"image_height\",\n",
    "        \"image_date_captured\",\n",
    "        \"image_coco_url\",\n",
    "        \"image_file_name\",\n",
    "        \"image_id\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Переименование колонок под соответствие первому датасету\n",
    "filter_ds_nocaps = filter_ds_nocaps.rename_columns({\"annotations_captions\": \"caption\"})\n",
    "\n",
    "filter_ds_nocaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение дву датасетов для дообучения моделей\n",
    "ds_train = concatenate_datasets([filter_ds_flickr30k, filter_ds_nocaps])\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция фильтрации описаний, что бы было одно\n",
    "def get_first_caption(example):\n",
    "    example[\"caption\"] = example[\"caption\"][0]\n",
    "    return example\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(get_first_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение предобработанного датасета\n",
    "ds_train.save_to_disk(\"datasets/captions_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобработанного датасета\n",
    "ds_train = load_from_disk(\"datasets/captions_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение датасета на обучающую и тестовую выборку\n",
    "ds = ds_train.train_test_split(test_size=0.1)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация нескольких примеров из обучающей выборки\n",
    "def plot_images(images, captions):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        caption = captions[i]\n",
    "        caption = \"\\n\".join(wrap(caption, 12))\n",
    "        plt.title(caption)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "sample_images_to_visualize = [np.array(train_ds[i][\"image\"]) for i in range(5)]\n",
    "sample_captions = [train_ds[i][\"caption\"] for i in range(5)]\n",
    "plot_images(sample_images_to_visualize, sample_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка базовой модели которую будем дообучать\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/git-base\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция предварительной обработки изображения (изменение размера и масштабирование пикселей) и токенизацию подписи\n",
    "def transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    captions = [x for x in example_batch[\"caption\"]]\n",
    "    inputs = processor(images=images, text=captions, padding=\"max_length\")\n",
    "    inputs.update({\"labels\": inputs[\"input_ids\"]})\n",
    "    return inputs\n",
    "\n",
    "\n",
    "train_ds.set_transform(transforms)\n",
    "test_ds.set_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение loss дообучения\n",
    "wer = load(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predicted = logits.argmax(-1)\n",
    "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
    "    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
    "    return {\"WER score\": wer_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задает аргументы дообучения модели\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"git-base-train\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=25,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_steps=500,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фиксируем все параметры для старта дообучения\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дообучение проводилось на GPU V100\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"models/git-base-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кастомный класс создания синтетического датасета\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, data, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(data_dir, img) for img in os.listdir(data_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image, caption = loader(image_path, self.data)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, caption\n",
    "\n",
    "\n",
    "def loader(path, data):\n",
    "    image = Image.open(path)\n",
    "    caption = data.loc[data[\"image\"] == os.path.basename(path), \"caption\"].values[0]\n",
    "    return image, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/captions_sin\"\n",
    "\n",
    "data = pd.read_csv(f\"{data_dir}/captions.csv\")\n",
    "\n",
    "ds_sin = CustomDataset(f\"{data_dir}/images\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики METEOR\n",
    "def metric_meteor(predicted_captions, reference_captions):\n",
    "    meteor = load(\"meteor\")\n",
    "    meteor_avg = meteor.compute(\n",
    "        predictions=predicted_captions, references=reference_captions\n",
    "    )\n",
    "\n",
    "    return meteor_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики ROUGE\n",
    "def metric_rouge(predicted_captions, reference_captions):\n",
    "    rouge = load(\"rouge\")\n",
    "    rouge_avg = rouge.compute(\n",
    "        predictions=predicted_captions, references=reference_captions\n",
    "    )\n",
    "\n",
    "    return rouge_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики WER\n",
    "def metric_wer(predicted_captions, reference_captions):\n",
    "    wer = load(\"wer\")\n",
    "    wer_avg = wer.compute(predictions=predicted_captions, references=reference_captions)\n",
    "\n",
    "    return wer_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дообученная (простая) модель генерации описания изображений (показатели снимались на GPU V100)\n",
    "model_name = \"models/git-base-train\"\n",
    "\n",
    "wandb.init(project=\"child_diary\", group=model_name, job_type=\"train\")\n",
    "\n",
    "# Загрузка модели генерации описаний изображений\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "predicted_captions = []\n",
    "reference_captions = []\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Выполнение предсказания модели\n",
    "for image, captions in ds_sin:\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    pred_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    predicted_captions.append(pred_caption)\n",
    "    reference_captions.append(captions)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "rouge_result = metric_rouge(predicted_captions, reference_captions)\n",
    "\n",
    "wandb.log(\n",
    "    {\n",
    "        \"METEOR\": metric_meteor(predicted_captions, reference_captions),\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-2\": rouge_result[\"rouge2\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"WER\": metric_wer(predicted_captions, reference_captions),\n",
    "        \"Speed 1 image\": (end_time - start_time) / len(ds_sin),\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
