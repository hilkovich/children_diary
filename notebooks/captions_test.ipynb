{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from evaluate import load\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кастомный класс создания синтетического датасета\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, data, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(data_dir, img) for img in os.listdir(data_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image, caption = loader(image_path, self.data)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, caption\n",
    "\n",
    "\n",
    "def loader(path, data):\n",
    "    image = Image.open(path)\n",
    "    caption = data.loc[data[\"image\"] == os.path.basename(path), \"caption\"].values[0]\n",
    "    return image, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/captions_sin\"\n",
    "\n",
    "data = pd.read_csv(f\"{data_dir}/captions.csv\")\n",
    "\n",
    "ds_sin = CustomDataset(f\"{data_dir}/images\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики METEOR\n",
    "def metric_meteor(predicted_captions, reference_captions):\n",
    "    meteor = load(\"meteor\")\n",
    "    meteor_avg = meteor.compute(\n",
    "        predictions=predicted_captions, references=reference_captions\n",
    "    )\n",
    "\n",
    "    return meteor_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики ROUGE\n",
    "def metric_rouge(predicted_captions, reference_captions):\n",
    "    rouge = load(\"rouge\")\n",
    "    rouge_avg = rouge.compute(\n",
    "        predictions=predicted_captions, references=reference_captions\n",
    "    )\n",
    "\n",
    "    return rouge_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет метрики WER\n",
    "def metric_wer(predicted_captions, reference_captions):\n",
    "    wer = load(\"wer\")\n",
    "    wer_avg = wer.compute(predictions=predicted_captions, references=reference_captions)\n",
    "\n",
    "    return wer_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Простая модель генерации описания изображений (показатели снимались на GPU V100)\n",
    "model_name = \"microsoft/git-base\"\n",
    "\n",
    "wandb.init(project=\"child_diary\", group=model_name, job_type=\"base\")\n",
    "\n",
    "# Загрузка модели генерации описаний изображений\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "predicted_captions = []\n",
    "reference_captions = []\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Выполнение предсказания модели\n",
    "for image, captions in ds_sin:\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    pred_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    predicted_captions.append(pred_caption)\n",
    "    reference_captions.append(captions)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "rouge_result = metric_rouge(predicted_captions, reference_captions)\n",
    "\n",
    "wandb.log(\n",
    "    {\n",
    "        \"METEOR\": metric_meteor(predicted_captions, reference_captions),\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-2\": rouge_result[\"rouge2\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"WER\": metric_wer(predicted_captions, reference_captions),\n",
    "        \"Speed 1 image\": (end_time - start_time) / len(ds_sin),\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя модель генерации описания изображений (показатели снимались на GPU V100)\n",
    "model_name = \"Salesforce/blip-image-captioning-large\"\n",
    "\n",
    "wandb.init(project=\"child_diary\", group=model_name, job_type=\"base\")\n",
    "\n",
    "# Загрузка модели генерации описаний изображений\n",
    "processor = BlipProcessor.from_pretrained(model_name)\n",
    "model = BlipForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "predicted_captions = []\n",
    "reference_captions = []\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Выполнение предсказания модели\n",
    "for image, captions in ds_sin:\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    predicted_captions.append(processor.decode(out[0], skip_special_tokens=True))\n",
    "    reference_captions.append(captions)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "rouge_result = metric_rouge(predicted_captions, reference_captions)\n",
    "\n",
    "wandb.log(\n",
    "    {\n",
    "        \"METEOR\": metric_meteor(predicted_captions, reference_captions),\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-2\": rouge_result[\"rouge2\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"WER\": metric_wer(predicted_captions, reference_captions),\n",
    "        \"Speed 1 image\": (end_time - start_time) / len(ds_sin),\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сложная модель генерации описания изображений (показатели снимались на GPU V100)\n",
    "model_name = \"abhijit2111/Pic2Story\"\n",
    "\n",
    "wandb.init(project=\"child_diary\", group=model_name, job_type=\"base\")\n",
    "\n",
    "# Загрузка модели генерации описаний изображений\n",
    "processor = BlipProcessor.from_pretrained(model_name)\n",
    "model = BlipForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "predicted_captions = []\n",
    "reference_captions = []\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Выполнение предсказания модели\n",
    "for image, captions in ds_sin:\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    predicted_captions.append(processor.decode(out[0], skip_special_tokens=True))\n",
    "    reference_captions.append(captions)\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "rouge_result = metric_rouge(predicted_captions, reference_captions)\n",
    "\n",
    "wandb.log(\n",
    "    {\n",
    "        \"METEOR\": metric_meteor(predicted_captions, reference_captions),\n",
    "        \"ROUGE-1\": rouge_result[\"rouge1\"],\n",
    "        \"ROUGE-2\": rouge_result[\"rouge2\"],\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"],\n",
    "        \"WER\": metric_wer(predicted_captions, reference_captions),\n",
    "        \"Speed 1 image\": (end_time - start_time) / len(ds_sin),\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
